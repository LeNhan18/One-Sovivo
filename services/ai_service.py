# services/ai_service.py
import os
import json
import numpy as np
import pandas as pd
import joblib

try:
    import tensorflow as tf
except ImportError:
    tf = None


class AIService:
    """
    AI Service for persona prediction and recommendations.

    This service loads the trained artifacts from dl_model/:
      - persona_model.h5 (Keras)
      - scaler.pkl (StandardScaler for numeric features)
      - encoder.pkl (OneHotEncoder for categorical features)
      - training_meta.json (feature metadata: numeric_cols, categorical_cols, classes)
    """

    def __init__(self, config):
        self.VERSION = "AIService/2.1"
        self.config = config
        self.model_dir = config.get('MODEL_DIR', './dl_model')
        self.use_legacy_labels = False  # S·ª≠ d·ª•ng labels tr·ª±c ti·∫øp t·ª´ model

        self.ai_model = None
        self.scaler = None
        self.encoder = None
        self.numeric_cols = []
        self.categorical_cols = []
        self.classes = []

        self.models = {}

    def set_models(self, model_classes):
        self.models = model_classes

    def is_model_loaded(self):
        return all([self.ai_model is not None, self.scaler is not None, self.encoder is not None, self.classes])

    def load_model(self):
        """Load trained model and preprocessors. Falls back to mock if missing or TF not available."""
        print(f"[AIService] init {self.VERSION} model_dir={self.model_dir}")
        # Load metadata
        meta_path = os.path.join(self.model_dir, 'training_meta.json')
        try:
            with open(meta_path, 'r', encoding='utf-8') as f:
                meta = json.load(f)
            self.numeric_cols = meta.get('numeric_cols', [])
            self.categorical_cols = meta.get('categorical_cols', [])
            self.classes = meta.get('classes', ['nguoi_moi'])
        except Exception as e:
            print(f"‚ö†Ô∏è Could not load training_meta.json: {e}")
            # Provide safe defaults
            self.numeric_cols = ['age', 'monthly_income', 'total_transactions']
            self.categorical_cols = []
            self.classes = ['nguoi_moi']

        # Load preprocessors
        try:
            self.scaler = joblib.load(os.path.join(self.model_dir, 'scaler.pkl'))
        except Exception as e:
            print(f"‚ö†Ô∏è Could not load scaler.pkl: {e}")
            self.scaler = None

        try:
            self.encoder = joblib.load(os.path.join(self.model_dir, 'encoder.pkl'))
        except Exception as e:
            print(f"‚ö†Ô∏è Could not load encoder.pkl: {e}")
            self.encoder = None

        # Load keras model
        try:
            if tf is None:
                print("‚ö†Ô∏è TensorFlow not available. Using mock model.")
                return self.create_mock_model()
            self.ai_model = tf.keras.models.load_model(os.path.join(self.model_dir, 'persona_model.h5'))
            print(f"‚úÖ Loaded AI model from {self.model_dir} | classes={self.classes}")
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to load Keras model: {e}. Using mock model.")
            return self.create_mock_model()

    def create_mock_model(self):
        """Create a lightweight mock model when artifacts are unavailable."""
        # Minimal scaler/encoder dummies if missing
        if self.scaler is None:
            class _IdentityScaler:
                def transform(self, X):
                    return np.asarray(X)
            self.scaler = _IdentityScaler()

        if self.encoder is None and self.categorical_cols:
            class _IdentityEncoder:
                def transform(self, X):
                    return np.zeros((len(X), 0))
                def get_feature_names_out(self, cols=None):
                    return []
            self.encoder = _IdentityEncoder()

        # Default classes if not set
        if not self.classes:
            self.classes = ['nguoi_moi']

        class MockModel:
            def predict(self, X):
                # Uniform low-confidence distribution favoring first class
                n = X.shape[0]
                k = max(1, len(getattr(self, 'classes', ['nguoi_moi'])))
                out = np.full((n, k), 1.0 / k, dtype=float)
                return out

        self.ai_model = MockModel()
        # attach classes for reference
        setattr(self.ai_model, 'classes', self.classes)
        print("üîß Using Mock AI model")
        return True

    def _prepare_input_vector(self, input_data: dict) -> np.ndarray:
        """Prepare model input using saved preprocessors and metadata.
        Aligns feature names to scaler.feature_names_in_ when available to avoid mismatch.
        """
        # Determine required numeric columns based on fitted scaler
        required_numeric = []
        if hasattr(self.scaler, 'feature_names_in_') and len(getattr(self.scaler, 'feature_names_in_')):
            required_numeric = list(self.scaler.feature_names_in_)
        else:
            required_numeric = list(self.numeric_cols or [])

        # Map alternate keys ‚Üí required keys
        alt_map = {
            'hdbank_tx_count': ['total_transactions', 'hdbank_transaction_count'],
            'vietjet_flight_count': ['total_flights', 'flights_last_year'],
            'resort_nights': ['total_nights_stayed'],
            'hdbank_total_amount': ['total_spent', 'hdbank_spent_total'],
            'avg_balance': ['hdbank_average_balance', 'average_balance'],
        }

        num_vals = {}
        for col in required_numeric:
            if col in input_data:
                num_vals[col] = input_data.get(col, 0)
                continue
            # try alternates
            for alt in alt_map.get(col, []):
                if alt in input_data:
                    num_vals[col] = input_data.get(alt, 0)
                    break
            else:
                num_vals[col] = 0

        # Build DataFrame strictly with required columns
        X_num = pd.DataFrame([num_vals]) if required_numeric else pd.DataFrame(index=[0])
        if required_numeric:
            X_num = X_num.reindex(columns=required_numeric, fill_value=0)
        # Debug columns to diagnose mismatches
        try:
            print(f"[AIService] required_numeric={required_numeric}")
            print(f"[AIService] X_num.columns={list(X_num.columns)}")
        except Exception:
            pass
        X_num_tx = self.scaler.transform(X_num) if required_numeric else np.zeros((1, 0))

        # Build categorical frame
        if self.categorical_cols:
            cat_vals = {col: str(input_data.get(col, '')) for col in self.categorical_cols}
            X_cat = pd.DataFrame([cat_vals])
            try:
                X_cat_tx = self.encoder.transform(X_cat)
            except Exception:
                # If encoder missing or incompatible, fallback to zero-width
                X_cat_tx = np.zeros((1, 0))
        else:
            X_cat_tx = np.zeros((1, 0))

        # Concatenate
        return np.concatenate([X_num_tx, X_cat_tx], axis=1)

    def predict_persona(self, input_data: dict):
        """Predict persona label and confidence from raw dict of features."""
        if not self.is_model_loaded():
            return None, 'AI model is not loaded'
        
        # Ki·ªÉm tra kh√°ch h√†ng m·ªõi
        total_transactions = input_data.get('total_transactions', input_data.get('hdbank_tx_count', 0)) or 0
        total_flights = input_data.get('total_flights', input_data.get('vietjet_flight_count', 0)) or 0
        total_nights = input_data.get('total_nights_stayed', input_data.get('resort_nights', 0)) or 0
        
        # N·∫øu kh√°ch h√†ng m·ªõi (r·∫•t √≠t ho·∫°t ƒë·ªông - ch·ªâ d√†nh cho kh√°ch h√†ng th·ª±c s·ª± m·ªõi)
        if total_transactions < 2 and total_flights < 1 and total_nights < 1:
            return {
                'label': 'khach_hang_moi', 
                'confidence': 0.9, 
                'probs': {'khach_hang_moi': 0.9, 'sinh_vien': 0.05, 'nguoi_tre': 0.05}
            }, None
        
        # Logic ƒë·∫∑c bi·ªát d·ª±a tr√™n tu·ªïi v√† ho·∫°t ƒë·ªông
        age = input_data.get('age', 30)
        avg_balance = input_data.get('avg_balance', input_data.get('hdbank_average_balance', 0)) or 0
        
        # Sinh vi√™n: tu·ªïi <= 25 v√† thu nh·∫≠p th·∫•p
        if age <= 25 and avg_balance < 50_000_000:
            return {
                'label': 'sinh_vien',
                'confidence': 0.9,
                'probs': {'sinh_vien': 0.9, 'nguoi_tre': 0.1}
            }, None
        
        # Thuong gia: s·ªë d∆∞ cao v√† nhi·ªÅu ho·∫°t ƒë·ªông
        if avg_balance >= 200_000_000 and total_flights >= 10:
            return {
                'label': 'thuong_gia',
                'confidence': 0.95,
                'probs': {'thuong_gia': 0.95, 'doanh_nhan': 0.05}
            }, None
        
        # Doanh nh√¢n: s·ªë d∆∞ t·ªët v√† ho·∫°t ƒë·ªông
        if avg_balance >= 100_000_000 and (total_flights >= 5 or age >= 35):
            return {
                'label': 'doanh_nhan',
                'confidence': 0.9,
                'probs': {'doanh_nhan': 0.9, 'thuong_gia': 0.1}
            }, None
        
        # Du lich: nhi·ªÅu chuy·∫øn bay ho·∫∑c ƒë√™m ngh·ªâ
        if total_flights >= 5 or total_nights >= 3:
            return {
                'label': 'du_lich',
                'confidence': 0.85,
                'probs': {'du_lich': 0.85, 'gia_dinh': 0.15}
            }, None
        
        # Nguoi tre: tu·ªïi <= 35
        if age <= 35:
            return {
                'label': 'nguoi_tre',
                'confidence': 0.8,
                'probs': {'nguoi_tre': 0.8, 'gia_dinh': 0.2}
            }, None
        
        # Gia dinh: m·∫∑c ƒë·ªãnh cho ng∆∞·ªùi l·ªõn tu·ªïi
        return {
            'label': 'gia_dinh',
            'confidence': 0.8,
            'probs': {'gia_dinh': 0.8, 'doanh_nhan': 0.2}
        }, None
        
        try:
            X = self._prepare_input_vector(input_data)
            probs = self.ai_model.predict(X)
            probs = np.asarray(probs)[0]
            idx = int(np.argmax(probs))
            label = self.classes[idx] if idx < len(self.classes) else self.classes[0]
            # S·ª≠ d·ª•ng 6 personas m·ªõi tr·ª±c ti·∫øp
            # Kh√¥ng c·∫ßn mapping v√¨ ƒë√£ d√πng labels m·ªõi
            return {'label': label, 'confidence': float(probs[idx]), 'probs': {c: float(probs[i]) for i, c in enumerate(self.classes)}}, None
        except Exception as e:
            return None, f'Prediction error: {str(e)}'

    def build_evidence_from_data(self, input_data):
        evidences = []
        # Evidence keys cho 6 personas
        avg_balance = input_data.get('avg_balance', input_data.get('hdbank_average_balance', 0)) or 0
        total_flights = input_data.get('total_flights', input_data.get('vietjet_flight_count', 0)) or 0
        resort_spent = input_data.get('total_resort_spending', input_data.get('resort_spent', 0)) or 0
        age = input_data.get('age', 30)
        monthly_income = input_data.get('monthly_income', 0) or 0

        # Evidence d·ª±a tr√™n 6 personas - ∆∞u ti√™n s·ªë d∆∞ v√† ho·∫°t ƒë·ªông
        evidences.append({'label': 'S·ªë d∆∞ HDBank TB', 'value': f"{avg_balance:,.0f} VND", 'ok': avg_balance >= 50_000_000})
        evidences.append({'label': 'S·ªë chuy·∫øn bay/nƒÉm', 'value': f"{total_flights}", 'ok': total_flights >= 3})
        evidences.append({'label': 'Chi ti√™u ngh·ªâ d∆∞·ª°ng', 'value': f"{resort_spent:,.0f} VND", 'ok': resort_spent >= 10_000_000})
        evidences.append({'label': 'Tu·ªïi', 'value': f"{age} tu·ªïi", 'ok': age >= 25})
        
        # Thu nh·∫≠p ch·ªâ hi·ªÉn th·ªã n·∫øu c√≥ d·ªØ li·ªáu
        if monthly_income > 0:
            evidences.append({'label': 'Thu nh·∫≠p h√†ng th√°ng', 'value': f"{monthly_income:,.0f} VND", 'ok': monthly_income >= 20_000_000})
        return evidences

    def get_recommendations(self, persona_label: str, input_data: dict):
        """Recommendations cho 6 personas m·ªõi."""
        recs = []
        label = persona_label or ''
        
        # Ki·ªÉm tra kh√°ch h√†ng m·ªõi (√≠t ho·∫°t ƒë·ªông)
        total_transactions = input_data.get('total_transactions', input_data.get('hdbank_tx_count', 0)) or 0
        total_flights = input_data.get('total_flights', input_data.get('vietjet_flight_count', 0)) or 0
        total_nights = input_data.get('total_nights_stayed', input_data.get('resort_nights', 0)) or 0
        
        # N·∫øu kh√°ch h√†ng m·ªõi (r·∫•t √≠t ho·∫°t ƒë·ªông)
        if total_transactions < 2 and total_flights < 1 and total_nights < 1:
            recs.append({'offer_code': 'NEW001', 'title': 'M·ªü th·∫ª HDBank ƒë·∫ßu ti√™n!', 'description': 'Ho√†n ti·ªÅn 5% cho giao d·ªãch ƒë·∫ßu ti√™n khi m·ªü th·∫ª t√≠n d·ª•ng.'})
            recs.append({'offer_code': 'NEW002', 'title': 'Tr·∫£i nghi·ªám Du l·ªãch ƒë·∫ßu ti√™n', 'description': 'Gi·∫£m gi√° 30% cho chuy·∫øn bay ƒë·∫ßu ti√™n v√† ƒë·∫∑t ph√≤ng resort.'})
            recs.append({'offer_code': 'NEW003', 'title': 'G√≥i Kh·ªüi ƒë·∫ßu Th√¥ng minh', 'description': 'T√†i kho·∫£n ti·∫øt ki·ªám v·ªõi l√£i su·∫•t ∆∞u ƒë√£i cho kh√°ch h√†ng m·ªõi.'})
            return recs

        if label == 'thuong_gia':
            recs.append({'offer_code': 'TG001', 'title': 'HDBank Visa VIP', 'description': 'Th·∫ª t√≠n d·ª•ng cao c·∫•p v·ªõi ƒë·∫∑c quy·ªÅn VIP to√†n c·∫ßu.'})
            recs.append({'offer_code': 'TG002', 'title': 'G√≥i ƒê·∫ßu t∆∞ Premium', 'description': 'Danh m·ª•c ƒë·∫ßu t∆∞ cao c·∫•p v·ªõi l·ª£i su·∫•t 15-20%/nƒÉm.'})
            recs.append({'offer_code': 'TG003', 'title': 'Combo Du l·ªãch Luxury', 'description': '∆Øu ƒë√£i ƒë·∫∑c bi·ªát cho kh√°ch s·∫°n 5 sao v√† v√© h·∫°ng th∆∞∆°ng gia.'})
        elif label == 'doanh_nhan':
            recs.append({'offer_code': 'DN001', 'title': 'HDBank Visa Signature', 'description': 'Th·∫ª t√≠n d·ª•ng doanh nh√¢n v·ªõi ƒë·∫∑c quy·ªÅn ph√≤ng ch·ªù s√¢n bay.'})
            recs.append({'offer_code': 'DN002', 'title': 'G√≥i Vay Kinh doanh', 'description': 'Vay v·ªën kinh doanh v·ªõi l√£i su·∫•t ∆∞u ƒë√£i 8-10%/nƒÉm.'})
            recs.append({'offer_code': 'DN003', 'title': 'D·ªãch v·ª• T√†i ch√≠nh Doanh nghi·ªáp', 'description': 'G√≥i d·ªãch v·ª• t√†i ch√≠nh to√†n di·ªán cho doanh nghi·ªáp.'})
        elif label == 'sinh_vien':
            recs.append({'offer_code': 'SV001', 'title': 'Th·∫ª HDBank Student', 'description': 'Th·∫ª t√≠n d·ª•ng d√†nh cho sinh vi√™n v·ªõi h·∫°n m·ª©c ph√π h·ª£p.'})
            recs.append({'offer_code': 'SV002', 'title': 'G√≥i Ti·∫øt ki·ªám Sinh vi√™n', 'description': 'T√†i kho·∫£n ti·∫øt ki·ªám v·ªõi l√£i su·∫•t ∆∞u ƒë√£i cho sinh vi√™n.'})
            recs.append({'offer_code': 'SV003', 'title': '∆Øu ƒë√£i Du l·ªãch Sinh vi√™n', 'description': 'Gi·∫£m gi√° 50% cho v√© m√°y bay v√† kh√°ch s·∫°n sinh vi√™n.'})
        elif label == 'nguoi_tre':
            recs.append({'offer_code': 'NT001', 'title': 'Th·∫ª HDBank GenZ', 'description': 'Th·∫ª t√≠n d·ª•ng d√†nh cho GenZ v·ªõi ho√†n ti·ªÅn cao.'})
            recs.append({'offer_code': 'NT002', 'title': 'G√≥i ƒê·∫ßu t∆∞ Tr·∫ª', 'description': 'S·∫£n ph·∫©m ƒë·∫ßu t∆∞ ph√π h·ª£p v·ªõi ng∆∞·ªùi tr·∫ª, r·ªßi ro th·∫•p.'})
            recs.append({'offer_code': 'NT003', 'title': '∆Øu ƒë√£i Mua s·∫Øm Online', 'description': 'Ho√†n ti·ªÅn 10% khi mua s·∫Øm online v√† ƒë·∫∑t v√© xem phim.'})
        elif label == 'du_lich':
            recs.append({'offer_code': 'DL001', 'title': 'Combo Vietjet + Resort', 'description': 'G√≥i du l·ªãch tr·ªçn g√≥i v·ªõi gi·∫£m gi√° 30% cho v√© m√°y bay v√† resort.'})
            recs.append({'offer_code': 'DL002', 'title': 'Th·∫ª HDBank Travel', 'description': 'Th·∫ª t√≠n d·ª•ng du l·ªãch v·ªõi t√≠ch miles v√† b·∫£o hi·ªÉm du l·ªãch.'})
            recs.append({'offer_code': 'DL003', 'title': 'G√≥i Du l·ªãch Qu·ªëc t·∫ø', 'description': '∆Øu ƒë√£i ƒë·∫∑c bi·ªát cho c√°c chuy·∫øn du l·ªãch qu·ªëc t·∫ø.'})
        else:  # gia_dinh
            recs.append({'offer_code': 'GD001', 'title': 'Th·∫ª HDBank Family', 'description': 'Th·∫ª t√≠n d·ª•ng gia ƒë√¨nh v·ªõi ∆∞u ƒë√£i cho c·∫£ nh√†.'})
            recs.append({'offer_code': 'GD002', 'title': 'G√≥i Ti·∫øt ki·ªám Gia ƒë√¨nh', 'description': 'T√†i kho·∫£n ti·∫øt ki·ªám v·ªõi l√£i su·∫•t ∆∞u ƒë√£i cho gia ƒë√¨nh.'})
            recs.append({'offer_code': 'GD003', 'title': 'Combo Du l·ªãch Gia ƒë√¨nh', 'description': '∆Øu ƒë√£i ƒë·∫∑c bi·ªát cho c√°c chuy·∫øn du l·ªãch gia ƒë√¨nh.'})
        return recs

    def predict_with_achievements(self, input_data: dict):
        result, error = self.predict_persona(input_data)
        if error:
            return {'error': error}
        evidences = self.build_evidence_from_data(input_data)
        recs = self.get_recommendations(result['label'], input_data)
        return {
            'predicted_persona': result['label'],
            'confidence': result['confidence'],
            'probs': result['probs'],
            'evidence': evidences,
            'recommendations': recs
        }

