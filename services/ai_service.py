# services/ai_service.py
import os
import pandas as pd
import numpy as np
import matplotlib

matplotlib.use('Agg')
import matplotlib.pyplot as plt
import joblib
import tensorflow as tf
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from models import get_models


class AIService:
    def __init__(self, db, model_dir):
        self.db = db
        self.model_dir = model_dir
        self.ai_model = None
        self.scaler = None
        self.encoder = None
        self.feature_columns = ['age', 'avg_balance', 'total_flights', 'is_business_flyer_int',
                                'total_nights_stayed', 'total_resort_spending']

        # Get model classes after initialization
        self.models = get_models()
        self.Customer = self.models['Customer']
        self.HDBankTransaction = self.models['HDBankTransaction']
        self.VietjetFlight = self.models['VietjetFlight']
        self.ResortBooking = self.models['ResortBooking']

    def load_model(self):
        """T·∫£i model ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán."""
        try:
            self.ai_model = tf.keras.models.load_model(os.path.join(self.model_dir, 'persona_model.h5'))
            self.scaler = joblib.load(os.path.join(self.model_dir, 'scaler.pkl'))
            self.encoder = joblib.load(os.path.join(self.model_dir, 'encoder.pkl'))
            print(f"‚úÖ ƒê√£ t·∫£i Model AI t·ª´ {self.model_dir}")
            return True
        except (IOError, OSError) as e:
            print(f"‚ö†Ô∏è L·ªói khi t·∫£i model: {e}. T·∫°o model m·ªõi...")
            return self.train_and_save_model()

    def create_mock_model(self):
        """T·∫°o model m·∫´u n·∫øu ch∆∞a c√≥ d·ªØ li·ªáu"""
        print("üîß T·∫°o Mock Model ƒë·ªÉ demo...")

        # Mock scaler v√† encoder
        self.scaler = StandardScaler()
        self.scaler.mean_ = np.array([35, 100000000, 10, 0.5, 3, 10000000])
        self.scaler.scale_ = np.array([10, 50000000, 8, 0.5, 2, 5000000])

        self.encoder = OneHotEncoder(sparse_output=False)
        self.encoder.categories_ = [np.array(['doanh_nhan', 'gia_dinh', 'nguoi_tre'])]

        # Mock model (s·ª≠ d·ª•ng logic ƒë∆°n gi·∫£n)
        class MockModel:
            def predict(self, X):
                results = []
                for row in X:
                    # Logic ƒë∆°n gi·∫£n d·ª±a tr√™n features
                    if row[1] > 200000000:  # avg_balance
                        results.append([0.8, 0.1, 0.1])  # doanh_nhan
                    elif row[0] < 30:  # age
                        results.append([0.1, 0.1, 0.8])  # nguoi_tre
                    else:
                        results.append([0.1, 0.8, 0.1])  # gia_dinh
                return np.array(results)

        self.ai_model = MockModel()

        # L∆∞u mock files
        if not os.path.exists(self.model_dir):
            os.makedirs(self.model_dir)
        joblib.dump(self.scaler, os.path.join(self.model_dir, 'scaler.pkl'))
        joblib.dump(self.encoder, os.path.join(self.model_dir, 'encoder.pkl'))
        return True

    def train_and_save_model(self):
        """Hu·∫•n luy·ªán v√† l∆∞u model Deep Learning t·ª´ MySQL data."""
        print("ü§ñ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán Model AI t·ª´ d·ªØ li·ªáu MySQL...")

        # L·∫•y d·ªØ li·ªáu t·ª´ MySQL
        customers_query = """
            SELECT c.customer_id, c.name, c.age, c.persona_type,
                   COALESCE(AVG(h.balance), 0) as avg_balance,
                   COALESCE(COUNT(DISTINCT v.flight_id), 0) as total_flights,
                   COALESCE(MAX(CASE WHEN v.ticket_class = 'business' THEN 1 ELSE 0 END), 0) as is_business_flyer,
                   COALESCE(SUM(r.nights_stayed), 0) as total_nights_stayed,
                   COALESCE(SUM(r.booking_value), 0) as total_resort_spending
            FROM customers c
            LEFT JOIN hdbank_transactions h ON c.customer_id = h.customer_id
            LEFT JOIN vietjet_flights v ON c.customer_id = v.customer_id
            LEFT JOIN resort_bookings r ON c.customer_id = r.customer_id
            WHERE c.persona_type IS NOT NULL
            GROUP BY c.customer_id, c.name, c.age, c.persona_type
        """

        merged_df = pd.read_sql(customers_query, self.db.engine)

        if merged_df.empty:
            print("üìä Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hu·∫•n luy·ªán. T·∫°o d·ªØ li·ªáu m·∫´u...")
            return self.create_mock_model()

        # Feature Engineering
        merged_df['is_business_flyer_int'] = merged_df['is_business_flyer'].astype(int)
        merged_df.fillna(0, inplace=True)

        X_raw = merged_df[self.feature_columns]
        y_raw = merged_df[['persona_type']]

        # Chu·∫©n h√≥a v√† m√£ h√≥a
        self.scaler = StandardScaler()
        X_scaled = self.scaler.fit_transform(X_raw)

        self.encoder = OneHotEncoder(sparse_output=False)
        y_encoded = self.encoder.fit_transform(y_raw)

        # X√¢y d·ª±ng v√† hu·∫•n luy·ªán model
        model = tf.keras.Sequential([
            tf.keras.layers.Input(shape=(X_scaled.shape[1],)),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(y_encoded.shape[1], activation='softmax')
        ])
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
        history = model.fit(X_scaled, y_encoded, epochs=15, batch_size=64, verbose=1)

        # L∆∞u tr·ªØ
        if not os.path.exists(self.model_dir):
            os.makedirs(self.model_dir)

        model.save(os.path.join(self.model_dir, 'persona_model.h5'))
        joblib.dump(self.scaler, os.path.join(self.model_dir, 'scaler.pkl'))
        joblib.dump(self.encoder, os.path.join(self.model_dir, 'encoder.pkl'))

        self.plot_and_save_metrics(history)
        self.ai_model = model
        print(f"‚úÖ Hu·∫•n luy·ªán Model th√†nh c√¥ng!")
        return True

    def plot_and_save_metrics(self, history):
        """V·∫Ω v√† l∆∞u bi·ªÉu ƒë·ªì accuracy v√† loss."""
        plt.figure(figsize=(12, 5))
        # Bi·ªÉu ƒë·ªì Accuracy
        plt.subplot(1, 2, 1)
        plt.plot(history.history['accuracy'], label='Training Accuracy')
        plt.title('Model Accuracy')
        plt.ylabel('Accuracy')
        plt.xlabel('Epoch')
        plt.legend(loc='lower right')
        # Bi·ªÉu ƒë·ªì Loss
        plt.subplot(1, 2, 2)
        plt.plot(history.history['loss'], label='Training Loss')
        plt.title('Model Loss')
        plt.ylabel('Loss')
        plt.xlabel('Epoch')
        plt.legend(loc='upper right')

        plt.tight_layout()
        metrics_path = os.path.join(self.model_dir, 'training_metrics.png')
        plt.savefig(metrics_path)
        plt.close()
        print(f"üìä ƒê√£ l∆∞u bi·ªÉu ƒë·ªì Metrics t·∫°i: {metrics_path}")

    def predict_persona(self, input_data):
        """D·ª± ƒëo√°n persona t·ª´ input data"""
        if not all([self.ai_model, self.scaler, self.encoder]):
            return None, "Model AI ch∆∞a s·∫µn s√†ng"

        input_df = pd.DataFrame([input_data])[self.feature_columns]
        input_scaled = self.scaler.transform(input_df)

        try:
            prediction_probs = self.ai_model.predict(input_scaled)
            predicted_index = np.argmax(prediction_probs, axis=1)[0]
            predicted_persona = self.encoder.categories_[0][predicted_index]
            return predicted_persona, None
        except Exception as e:
            # Fallback prediction
            if input_data['avg_balance'] > 200000000:
                return 'doanh_nhan', None
            elif input_data['age'] < 30:
                return 'nguoi_tre', None
            else:
                return 'gia_dinh', None

    def build_evidence(self, profile):
        """Sinh evidence ƒë·ªÉ gi·∫£i th√≠ch d·ª± ƒëo√°n AI."""
        evidences = []
        avg_balance = profile.get('hdbank_summary', {}).get('average_balance', 0) or 0
        is_biz = profile.get('vietjet_summary', {}).get('is_business_flyer', False)
        total_flights = profile.get('vietjet_summary', {}).get('total_flights_last_year', 0) or 0
        resort_spending = profile.get('resort_summary', {}).get('total_spending', 0) or 0

        evidences.append({
            'label': 'S·ªë d∆∞ trung b√¨nh',
            'value': f"{avg_balance:,.0f} VND",
            'ok': avg_balance >= 100_000_000
        })
        evidences.append({
            'label': 'Bay h·∫°ng th∆∞∆°ng gia',
            'value': 'C√≥' if is_biz else 'Kh√¥ng',
            'ok': bool(is_biz)
        })
        evidences.append({
            'label': 'S·ªë chuy·∫øn bay/nƒÉm',
            'value': f"{total_flights} chuy·∫øn",
            'ok': total_flights >= 5
        })
        evidences.append({
            'label': 'Chi ti√™u ngh·ªâ d∆∞·ª°ng',
            'value': f"{resort_spending:,.0f} VND",
            'ok': resort_spending >= 20_000_000
        })

        return evidences

    def get_recommendations(self, predicted_persona, profile):
        """
        H·ªÜ TH·ªêNG ƒê·ªÄ XU·∫§T ƒêA T·∫¶NG
        T·∫°o ƒë·ªÅ xu·∫•t d·ª±a tr√™n persona, t√≠n hi·ªáu h√†nh vi v√† ch·∫•m ƒëi·ªÉm.
        """
        all_recommendations = {}

        # --- T·∫ßng 1: ƒê·ªÅ xu·∫•t d·ª±a tr√™n Ph√¢n kh√∫c (Persona-based) ---
        persona_recs = self._get_persona_recommendations(predicted_persona)
        for rec in persona_recs:
            all_recommendations[rec['offer_code']] = rec

        # --- T·∫ßng 2: ƒê·ªÅ xu·∫•t d·ª±a tr√™n T√≠n hi·ªáu (Trigger-based) ---
        trigger_recs = self._get_trigger_recommendations(profile)
        for rec in trigger_recs:
            all_recommendations[rec['offer_code']] = rec

        # --- T·∫ßng 3: Ch·∫•m ƒëi·ªÉm & X·∫øp h·∫°ng ---
        ranked_recs = sorted(
            all_recommendations.values(),
            key=lambda x: x.get('score', 0),
            reverse=True
        )

        # Tr·∫£ v·ªÅ Top 3 ƒë·ªÅ xu·∫•t t·ªët nh·∫•t
        return ranked_recs[:3]

    def _get_persona_recommendations(self, persona):
        """Helper: L·∫•y c√°c ƒë·ªÅ xu·∫•t n·ªÅn t·∫£ng theo persona."""
        recs = []
        if persona == 'doanh_nhan':
            recs.append({
                'offer_code': 'DN001', 'score': 70,
                'title': 'M·ªü th·∫ª HDBank Visa Signature',
                'description': 'T·∫≠n h∆∞·ªüng ƒë·∫∑c quy·ªÅn ph√≤ng ch·ªù s√¢n bay v√† c√°c ∆∞u ƒë√£i golf cao c·∫•p.'
            })
            recs.append({
                'offer_code': 'DN003', 'score': 60,
                'title': 'G√≥i ƒê·∫ßu t∆∞ Tr√°i phi·∫øu Doanh nghi·ªáp',
                'description': 'L·ª£i su·∫•t h·∫•p d·∫´n v√† an to√†n cho d√≤ng ti·ªÅn nh√†n r·ªói c·ªßa b·∫°n.'
            })
        elif persona == 'gia_dinh':
            recs.append({
                'offer_code': 'GD001', 'score': 70,
                'title': 'Combo Du l·ªãch H√® Vietjet',
                'description': 'Gi·∫£m gi√° 30% cho c·∫£ gia ƒë√¨nh khi ƒë·∫∑t v√© m√°y bay v√† kh√°ch s·∫°n qua HDBank App.'
            })
            recs.append({
                'offer_code': 'GD002', 'score': 65,
                'title': 'G√≥i Ti·∫øt ki·ªám "Ch·∫Øp c√°nh T∆∞∆°ng lai"',
                'description': 'B·∫Øt ƒë·∫ßu t√≠ch l≈©y cho vi·ªác h·ªçc c·ªßa con b·∫°n v·ªõi l√£i su·∫•t ∆∞u ƒë√£i.'
            })
        elif persona == 'nguoi_tre':
            recs.append({
                'offer_code': 'NT001', 'score': 70,
                'title': 'M·ªü th·∫ª t√≠n d·ª•ng ƒë·∫ßu ti√™n',
                'description': 'B·∫Øt ƒë·∫ßu x√¢y d·ª±ng l·ªãch s·ª≠ t√≠n d·ª•ng c·ªßa b·∫°n v·ªõi th·∫ª HDBank Vietjet Platinum.'
            })
        return recs

    def _get_trigger_recommendations(self, profile):
        """Helper: Qu√©t profile ƒë·ªÉ t√¨m c√°c t√≠n hi·ªáu v√† k√≠ch ho·∫°t ƒë·ªÅ xu·∫•t."""
        recs = []

        # L·∫•y c√°c ch·ªâ s·ªë ch√≠nh t·ª´ profile
        avg_balance = profile.get('hdbank_summary', {}).get('average_balance', 0)
        total_flights = profile.get('vietjet_summary', {}).get('total_flights_last_year', 0)
        resort_spending = profile.get('resort_summary', {}).get('total_spending', 0)
        has_loan = profile.get('hdbank_summary', {}).get('total_loan_amount', 0) > 0

        # T√≠n hi·ªáu 1: Kh√°ch h√†ng ti·ªÅm nƒÉng cao cho th·∫ª VIP
        if avg_balance > 500_000_000 and total_flights > 10:
            recs.append({
                'offer_code': 'TRG001', 'score': 100,
                'title': 'N√¢ng c·∫•p mi·ªÖn ph√≠ HDBank Visa Signature',
                'description': 'Tri √¢n s·ª± g·∫Øn b√≥, t·∫≠n h∆∞·ªüng ƒë·∫∑c quy·ªÅn ph√≤ng ch·ªù th∆∞∆°ng gia mi·ªÖn ph√≠.'
            })

        # T√≠n hi·ªáu 2: Kh√°ch h√†ng ti·ªÅm nƒÉng cho BƒêS ngh·ªâ d∆∞·ª°ng
        if resort_spending > 50_000_000 and avg_balance > 1_000_000_000:
            recs.append({
                'offer_code': 'TRG002', 'score': 95,
                'title': 'ƒê·∫∑c quy·ªÅn tham d·ª± s·ª± ki·ªán BƒêS Sovico',
                'description': 'Nh·∫≠n v√© m·ªùi tham d·ª± s·ª± ki·ªán ra m·∫Øt d·ª± √°n b·∫•t ƒë·ªông s·∫£n ngh·ªâ d∆∞·ª°ng m·ªõi nh·∫•t.'
            })

        # T√≠n hi·ªáu 3: Kh√°ch h√†ng c√≥ ti·ªÅn nh∆∞ng ch∆∞a bay
        if total_flights == 0 and avg_balance > 200_000_000:
            recs.append({
                'offer_code': 'TRG003', 'score': 90,
                'title': 'Tr·∫£i nghi·ªám bay Vietjet v·ªõi ∆∞u ƒë√£i 50%',
                'description': 'T·∫∑ng voucher gi·∫£m 50% cho chuy·∫øn bay n·ªôi ƒë·ªãa ƒë·∫ßu ti√™n c·ªßa b·∫°n.'
            })

        # T√≠n hi·ªáu 4: Ng∆∞·ªùi tr·∫ª c√≥ thu nh·∫≠p ·ªïn ƒë·ªãnh, ti·ªÅm nƒÉng vay
        if (profile.get('basic_info', {}).get('age', 30) < 30) and (avg_balance > 20_000_000) and not has_loan:
            recs.append({
                'offer_code': 'TRG004', 'score': 85,
                'title': 'G√≥i vay ti√™u d√πng tr·∫£ g√≥p 0%',
                'description': 'S·ªü h·ªØu ngay c√°c s·∫£n ph·∫©m c√¥ng ngh·ªá m·ªõi nh·∫•t v·ªõi ∆∞u ƒë√£i tr·∫£ g√≥p 0% qua HD Saison.'
            })

        return recs
